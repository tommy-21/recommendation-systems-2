{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dfrey/MyCode/blob/master/NN_based_recommender_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sT8AyHRMNh41"
   },
   "source": [
    "# Basic recommender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f-reQ11gbLB"
   },
   "source": [
    "In this tutorial, we build a simple matrix factorization model using the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/) with TFRS. We can use this model to recommend movies for a given user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA00wBE2Ntdm"
   },
   "source": [
    "### Import TFRS\n",
    "\n",
    "First, install and import TFRS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yzAaM85Z12D"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets\n",
    "!pip install -q jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3oYt3R6Nr9l"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCxQ1CZcO2wh"
   },
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvC9VVXOHlXn"
   },
   "outputs": [],
   "source": [
    "ratings_full = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "\n",
    "user_ids = ratings_full.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = np.unique(list(tfds.as_numpy(user_ids)))\n",
    "\n",
    "movie_titles = ratings_full.map(lambda x: x[\"movie_title\"])\n",
    "unique_movie_titles = np.unique(list(tfds.as_numpy(movie_titles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgKXUeSO868N"
   },
   "source": [
    "> ### TODO\n",
    ">\n",
    "> Display the ten first examples to explore the list of available informations\n",
    ">\n",
    "> Usefull: `Dataset.take(count)`, `tfds.as_numpy()`, `tfds.as_dataframe()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWXpgQVzHpwf"
   },
   "outputs": [],
   "source": [
    "print(unique_user_ids.size)\n",
    "print(unique_movie_titles.size)\n",
    "print(ratings_full.cardinality().numpy()/(unique_user_ids.size*unique_movie_titles.size))\n",
    "# TODO add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm-Ummuy93Tb"
   },
   "source": [
    "Restrict the dataset to used features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-mxBYjdO5m7"
   },
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = ratings_full.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "    \"timestamp\": x[\"timestamp\"],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXCQpH2LMSf0"
   },
   "source": [
    "Split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oj5OYXLjMSqA"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrch6rVBOB9Q"
   },
   "source": [
    "### Define a model\n",
    "\n",
    "We can define a prediction model by inheriting from `tf.keras.Model` and implementing the `call` method.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Draw the model (you can draw it on a piece of paper and scan it, or take a picture of it, and include your picture in the zip file you submit. You should name your file either `[lastname1]-[lastname2]-modeldrawing.jpg/pdf/...` or `[firstname]-[lastname]-modeldrawing.jpg/pdf/...` depending on whether you worked in pairs or alone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFalJDcOU4_d"
   },
   "outputs": [],
   "source": [
    "class DotRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.layers.Dot(axes=(1))\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    user_embedding = self.user_embeddings(features[\"user_id\"])\n",
    "    movie_embedding = self.movie_embeddings(features[\"movie_title\"])\n",
    "\n",
    "    return self.ratings((user_embedding, movie_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Y6hsvwWc7ZR"
   },
   "outputs": [],
   "source": [
    "DotRankingModel()({\"user_id\": [\"42\",\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\", \"Strictly Ballroom (1992)\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnm3Monk-HbG"
   },
   "source": [
    "We can define a TFRS model by inheriting from `tfrs.Model` and implementing the `compute_loss` method.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Explain the role played by this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXOntFjKdjaW"
   },
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_model: tf.keras.Model):\n",
    "    super().__init__()\n",
    "    self.ranking_model = rating_model\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model(features)\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"user_rating\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zca6clv-dWC"
   },
   "source": [
    "## Fit and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4jBtrYAU8LE"
   },
   "outputs": [],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(DotRankingModel())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train and test\n",
    "dot_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=10,\n",
    "    verbose=1)\n",
    "\n",
    "test_accuracy = dot_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
    "print(f\"RMSE: {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caiEkjUGfGVd"
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"RMSE\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8_8re05-taq"
   },
   "source": [
    "> ### TODO\n",
    ">\n",
    "> Comment the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### TODO\n",
    "> Can you make the model more accurate? How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFyPZmqQl4Du"
   },
   "source": [
    "# More complex link between user's and item's representations\n",
    "\n",
    "Let replace the dot product between user's and item's representations by a fully connected layer of size 64, followed by a fully connected layer with a unique output.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> - Define the layer and adapt the `call` method\n",
    "> - Choose carefully the activation functions of the layers\n",
    ">\n",
    "> Useful: `tf.keras.Sequential`, `tf.keras.Dense`, `tf.concat`\n",
    "> \n",
    "> You can alo checkout the Tensorflow/Keras tutorial here https://www.tensorflow.org/guide/keras/sequential_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65LzTZe8mYbs"
   },
   "outputs": [],
   "source": [
    "class OneLayerRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = # TODO here\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    user_embedding = self.user_embeddings(features[\"user_id\"])\n",
    "    movie_embedding = self.movie_embeddings(features[\"movie_title\"])\n",
    "\n",
    "    return self.ratings(# TODO here. Note keras.layer.Dot was taking a tuple as input, now your model takes something else. Useful tool: tf.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAx8po39mYj-"
   },
   "outputs": [],
   "source": [
    "OneLayerRankingModel()({\"user_id\": [\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MomtyxVvmY0k"
   },
   "outputs": [],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(OneLayerRankingModel())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train and test\n",
    "one_layer_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=10,\n",
    "    verbose=1)\n",
    "\n",
    "test_accuracy = one_layer_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
    "print(f\"RMSE: {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCLZjF9Nok4S"
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
    "plt.plot(one_layer_model_history.history[\"val_root_mean_squared_error\"], label=\"one layer\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"RMSE\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooZ4g25P0YSs"
   },
   "source": [
    "# Taking advantage of context features\n",
    "\n",
    "Let use timestamps of the ratings and movie titles to enrich the input of the model.\n",
    "\n",
    "Some preliminary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSeZJBJI4rUl"
   },
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings_full.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xe9ghj84-ri"
   },
   "source": [
    "New user model.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Draw and explain the role played by the components of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLcCzx-SzSBl"
   },
   "outputs": [],
   "source": [
    "class EnrichedRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Building blocks to compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self.timestamp_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "        tf.keras.layers.Embedding(len(timestamp_buckets) + 1, embedding_dimension),\n",
    "    ])\n",
    "\n",
    "    self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "        axis=None\n",
    "    )\n",
    "    self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "    # Building blocks to compute embeddings for movies.\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "      max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embeddings = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, embedding_dimension, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer.adapt(unique_movie_titles)\n",
    "\n",
    "\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    user_embedding = tf.concat([\n",
    "        self.user_embeddings(features[\"user_id\"]),\n",
    "        self.timestamp_embeddings(features[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(features[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)\n",
    "\n",
    "    movie_embedding = tf.concat([\n",
    "        self.movie_embeddings(features[\"movie_title\"]),\n",
    "        self.title_text_embeddings(features[\"movie_title\"]),\n",
    "    ], axis=1)\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L9AP2s-1GCj"
   },
   "outputs": [],
   "source": [
    "EnrichedRankingModel()({\"user_id\": [\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\"], \"timestamp\":[879024327]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPrbGZZ22bzX"
   },
   "outputs": [],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(EnrichedRankingModel())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train and test\n",
    "enriched_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=10,\n",
    "    verbose=1)\n",
    "\n",
    "test_accuracy = enriched_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
    "print(f\"RMSE: {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqpESO5v2bzY"
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
    "plt.plot(one_layer_model_history.history[\"val_root_mean_squared_error\"], label=\"one layer\")\n",
    "plt.plot(enriched_model_history.history[\"val_root_mean_squared_error\"], label=\"enriched\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"RMSE\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mdYyJSs7QPY"
   },
   "source": [
    "# More comple models\n",
    "\n",
    "\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Build and test more complex models:\n",
    "> - with more layers to link user's and item's representation\n",
    "> - integrating more contextual information: user's age, movie's genre, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyVMhMsnRcN0"
   },
   "source": [
    "# Copyright\n",
    "\n",
    "Several section of this notebook originate from notebooks under the following copyright:\n",
    "\n",
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfR1i3oKRcOD"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
